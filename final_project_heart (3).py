# -*- coding: utf-8 -*-
"""FINAL PROJECT HEART

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10j1K3HBHeMc1L3o1p3uxfK3r0tOGXmxa
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('heart.csv')
df

df.info()

df.describe()

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

X = df.drop('target', axis=1)
y = df['target']

"""train test split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42,stratify=y )

X_train.shape

X_test.shape

y_train.shape

y_test.shape

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#modilfiting
from sklearn.metrics import accuracy_score

"""LOGISTIC"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(X_train,y_train)

Y_pred_lr = lr.predict(X_test)

Y_pred_lr.shape

score_lr = round(accuracy_score(Y_pred_lr,y_test)*100,2)

print("The accuracy score achieved using Logistic Regression is: "+str(score_lr)+" %")

from sklearn.metrics import confusion_matrix, classification_report

cm = confusion_matrix(y_test, Y_pred_lr)
print("Confusion Matrix:\n", cm)

print("\nClassification Report:\n", classification_report(y_test, Y_pred_lr))

"""SVM

"""

from sklearn import svm

sv = svm.SVC(kernel='linear')

sv.fit(X_train, y_train)

Y_pred_svm = sv.predict(X_test)

Y_pred_svm.shape

score_svm = round(accuracy_score(Y_pred_svm,y_test)*100,2)

print("The accuracy score achieved using Linear SVM is: "+str(score_svm)+" %")

from sklearn.metrics import confusion_matrix, classification_report

cm_svm = confusion_matrix(y_test, Y_pred_svm)
print("Confusion Matrix (SVM):\n", cm_svm)

print("\nClassification Report (SVM):\n", classification_report(y_test, Y_pred_svm))

"""RANDOMFOREST"""

from sklearn.ensemble import RandomForestClassifier

max_accuracy = 0


for x in range(2000):
    rf = RandomForestClassifier(random_state=x)
    rf.fit(X_train,y_train)
    Y_pred_rf = rf.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_rf,y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x

#print(max_accuracy)
#print(best_x)

rf = RandomForestClassifier(random_state=best_x)
rf.fit(X_train,y_train)
Y_pred_rf = rf.predict(X_test)

score_rf = round(accuracy_score(Y_pred_rf,y_test)*100,2)

print("The accuracy score achieved using Decision Tree is: "+str(score_rf)+" %")

from sklearn.metrics import confusion_matrix, classification_report

cm_rf = confusion_matrix(y_test, Y_pred_rf)
print("Confusion Matrix (rf):\n", cm_rf)

print("\nClassification Report (rf):\n", classification_report(y_test, Y_pred_rf))

"""K Nearest Neighbors"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train,y_train)
Y_pred_knn=knn.predict(X_test)

score_knn = round(accuracy_score(Y_pred_knn,y_test)*100,2)

print("The accuracy score achieved using KNN is: "+str(score_knn)+" %")

from sklearn.metrics import confusion_matrix, classification_report

cm_kn = confusion_matrix(y_test, Y_pred_knn)
print("Confusion Matrix (kn:\n", cm_kn)

print("\nClassification Report (kn):\n", classification_report(y_test, Y_pred_knn))

"""Decision Tree

"""

from sklearn.tree import DecisionTreeClassifier

max_accuracy = 0


for x in range(2000):
    dt = DecisionTreeClassifier(random_state=x)
    dt.fit(X_train,y_train)
    Y_pred_dt = dt.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_dt,y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x

#print(max_accuracy)
#print(best_x)


dt = DecisionTreeClassifier(random_state=best_x)
dt.fit(X_train,y_train)
Y_pred_dt = dt.predict(X_test)

score_dt = round(accuracy_score(Y_pred_dt,y_test)*100,2)

print("The accuracy score achieved using Decision Tree is: "+str(score_dt)+" %")

from sklearn.metrics import confusion_matrix, classification_report

cm_dt = confusion_matrix(y_test, Y_pred_dt)
print("Confusion Matrix (dt):\n", cm_dt)

print("\nClassification Report (dt):\n", classification_report(y_test, Y_pred_dt))

"""Naive Bayes

"""

from sklearn.naive_bayes import GaussianNB

nb = GaussianNB()

nb.fit(X_train,y_train)

Y_pred_nb = nb.predict(X_test)

score_nb = round(accuracy_score(Y_pred_nb,y_test)*100,2)

print("The accuracy score achieved using Naive Bayes is: "+str(score_nb)+" %")

from sklearn.metrics import confusion_matrix, classification_report

cm_nb = confusion_matrix(y_test, Y_pred_nb)
print("Confusion Matrix (nb):\n", cm_nb)

print("\nClassification Report (nb):\n", classification_report(y_test, Y_pred_nb))

import matplotlib.pyplot as plt
import seaborn as sns

y_preds = {
    "Logistic": Y_pred_lr,
    "SVM": Y_pred_svm,
    "Random Forest": Y_pred_rf,
    "KNN": Y_pred_knn,
    "Decision Tree": Y_pred_dt,
    "Naive Bayes": Y_pred_nb
}

plt.figure(figsize=(8, 5))
for idx, (name, y_pred) in enumerate(y_preds.items(), 1):
    cm = confusion_matrix(y_test, y_pred)
    plt.subplot(3, 2, idx)
    sns.heatmap(cm, annot=True, fmt='g', cmap="Blues")
    plt.title(name)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')

plt.tight_layout()
plt.show()

"""Output final"""

scores = [score_lr,score_nb,score_svm,score_knn,score_dt,score_rf]
algorithms = ["Logistic Regression","Naive Bayes","Support Vector Machine","K-Nearest Neighbors","Decision Tree","Random Forest"]

for i in range(len(algorithms)):
    print("The accuracy score achieved using "+algorithms[i]+" is: "+str(scores[i])+" %")

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

accuracy_lr   = 81.58
accuracy_nb   = 80.26
accuracy_svm  = 81.58
accuracy_knn  = 63.16
accuracy_dt   = 78.95
accuracy_rf   = 84.21

df_acc = pd.DataFrame({
    'Algorithm': ['Logistic Regression', 'Naive Bayes', 'Support Vector Machine',
                  'K-Nearest Neighbors', 'Decision Tree', 'Random Forest'],
    'Accuracy (%)': [accuracy_lr, accuracy_nb, accuracy_svm,
                     accuracy_knn, accuracy_dt, accuracy_rf]
})

sns.set(rc={'figure.figsize': (10, 5)})
sns.barplot(x='Algorithm', y='Accuracy (%)', data=df_acc, palette='Set2', alpha=0.8)

plt.xlabel("Algorithm")
plt.ylabel("Accuracy (%)")
plt.ylim(50, 90)
plt.xticks(rotation=45)
plt.show()

import joblib

# Train the model after splitting and scaling the data
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_scaled, y_train)

# Save the trained model to a file
joblib.dump(rf, "heart_model.pkl")

# Save the scaler to use it later during prediction
joblib.dump(scaler, "scaler.pkl")

# Save the list of feature names to ensure correct input order
joblib.dump(X.columns.tolist(), "cols.pkl")

print("Model, scaler, and column names have been saved successfully.")

!ls

import joblib
model = joblib.load("heart_model.pkl")
print(model)

import gradio as gr
import pandas as pd
import joblib

# Load model and components
model = joblib.load("heart_model.pkl")
scaler = joblib.load("scaler.pkl")
columns = joblib.load("cols.pkl")

# Prediction function
def predict_heart_disease(age, sex, cp, trestbps, chol, fbs, restecg,
                          thalach, exang, oldpeak, slope, ca, thal):
    df = pd.DataFrame([[age, sex, cp, trestbps, chol, fbs, restecg,
                        thalach, exang, oldpeak, slope, ca, thal]], columns=columns)
    df_scaled = scaler.transform(df)
    prediction = model.predict(df_scaled)[0]
    return "Patient HAS heart disease" if prediction == 1 else "Patient does NOT have heart disease"

# Launch interface
gr.Interface(
    fn=predict_heart_disease,
    inputs=[
        gr.Number(label="Age (age)"),
        gr.Radio([0, 1], label="Sex (sex)"),
        gr.Dropdown([0, 1, 2, 3], label="Chest Pain Type (cp)"),
        gr.Number(label="Resting Blood Pressure (trestbps)"),
        gr.Number(label="Cholesterol (chol)"),
        gr.Radio([0, 1], label="Fasting Blood Sugar > 120 (fbs)"),
        gr.Dropdown([0, 1, 2], label="Rest ECG (restecg)"),
        gr.Number(label="Max Heart Rate (thalach)"),
        gr.Radio([0, 1], label="Exercise Induced Angina (exang)"),
        gr.Number(label="Oldpeak (oldpeak)"),
        gr.Dropdown([0, 1, 2], label="Slope (slope)"),
        gr.Slider(0, 3, step=1, label="Number of Vessels Colored (ca)"),
        gr.Dropdown([0, 1, 2, 3, 6, 7], label="Thalassemia (thal)"),], outputs="text", title="Heart Disease Predictor").launch(share=True)

